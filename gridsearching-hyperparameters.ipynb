{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Introduction to Gridsearching Hyperparameters\n",
    "\n",
    "\n",
    "### Learning Objective\n",
    "- Understand what the terms gridsearch and hyperparameter refer to.\n",
    "- Understand how to manually build a gridsearching procedure.\n",
    "- Apply sklearn's `GridSearchCV` object with basketball data to optimize a KNN model.\n",
    "- Practice using and evaluating attributes of the gridsearch object.\n",
    "- Understand the pitfalls of searching large hyperparameter spaces.\n",
    "- Practice the gridsearch procedure independently optimizing regularized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## What is \"Gridsearching\"? What are \"hyperparameters\"?\n",
    "\n",
    "---\n",
    "\n",
    "Models often have specifications that can be set. For example, when we choose a linear regression, we may decide to add a penalty to the loss function such as the Ridge or the Lasso. Those penalties require the regularization strength, alpha, to be set. \n",
    "\n",
    "**Model parameters are called hyperparameters.**\n",
    "\n",
    ">What hyperparameters do you know for k-nearest neighbours?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hyperparameters are different than the parameters of the model resulting from a fit, such as the coefficients. The hyperparameters are set prior to the fit and determine the behavior of the model.\n",
    "\n",
    "There are often more than one kind of hyperparameter to set for a model.\n",
    "\n",
    "**The search for the optimal set of hyperparameters is called gridsearching.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gridsearching gets its name from the fact that we are searching over a \"grid\" of parameters. For example, imagine the `n_neighbors` hyperparameters on the x-axis and `weights` on the y-axis, and we need to test all points on the grid.\n",
    "\n",
    "**Gridsearching uses cross-validation internally to evaluate the performance of each set of hyperparameters.** More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='basketball-data'></a>\n",
    "\n",
    "## Basketball data\n",
    "\n",
    "---\n",
    "\n",
    "To explore the process of gridsearching over sets of hyperparameters, we will use some basketball data. The data below has statistics for 4 different seasons of NBA basketball: 2013-2016.\n",
    "- This data includes aggregate statistical data for each game. \n",
    "- The data of each game is aggregated by match for all players.\n",
    "- Scraped from http://www.basketball-reference.com\n",
    "\n",
    "Many of the columns in the dataset represent the mean of a statistic across the last 10 games, for example. Non-target statistics are for *prior* games, they do not include information about player performance in the current game.\n",
    "\n",
    "**We are interested in predicting whether the home team will win the game or not.** This is a classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load the data and create the target and predictor matrix\n",
    "- The target will be a binary column of whether the home team wins.\n",
    "- The predictors should be numeric statistics columns.\n",
    "\n",
    "We're going to exclude these columns from the predictor matrix:\n",
    "\n",
    "    ['GameId','GameDate','GameTime','HostName',\n",
    "     'GuestName','total_score','total_line','game_line',\n",
    "     'winner','loser','host_wins','Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/basketball_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GameId</th>\n",
       "      <th>GameDate</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>HostName</th>\n",
       "      <th>GuestName</th>\n",
       "      <th>total_score</th>\n",
       "      <th>total_line</th>\n",
       "      <th>game_line</th>\n",
       "      <th>Host_HostRank</th>\n",
       "      <th>...</th>\n",
       "      <th>gPTS_avg10</th>\n",
       "      <th>gTS%_avg10</th>\n",
       "      <th>g3PAR_avg10</th>\n",
       "      <th>gFTr_avg10</th>\n",
       "      <th>gDRB%_avg10</th>\n",
       "      <th>gTRB%_avg10</th>\n",
       "      <th>gAST%_avg10</th>\n",
       "      <th>gSTL%_avg10</th>\n",
       "      <th>gBLK%_avg10</th>\n",
       "      <th>gDRtg_avg10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212090LAL</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>6:30 pm</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>227.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>69.22</td>\n",
       "      <td>50.05</td>\n",
       "      <td>61.57</td>\n",
       "      <td>8.63</td>\n",
       "      <td>10.31</td>\n",
       "      <td>110.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100PHI</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>201.0</td>\n",
       "      <td>186.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>90.3</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>71.46</td>\n",
       "      <td>49.48</td>\n",
       "      <td>59.83</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.46</td>\n",
       "      <td>107.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100HOU</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>240.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>74.26</td>\n",
       "      <td>50.99</td>\n",
       "      <td>61.82</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.85</td>\n",
       "      <td>101.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110BRK</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>197.0</td>\n",
       "      <td>195.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>100.3</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>74.23</td>\n",
       "      <td>47.88</td>\n",
       "      <td>52.07</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.64</td>\n",
       "      <td>109.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110DET</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:30 pm</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>101.1</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>68.45</td>\n",
       "      <td>50.40</td>\n",
       "      <td>56.33</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>114.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season        GameId    GameDate GameTime            HostName  \\\n",
       "0    2013  201212090LAL  2012-12-09  6:30 pm  Los Angeles Lakers   \n",
       "1    2013  201212100PHI  2012-12-10  7:00 pm  Philadelphia 76ers   \n",
       "2    2013  201212100HOU  2012-12-10  7:00 pm     Houston Rockets   \n",
       "3    2013  201212110BRK  2012-12-11  7:00 pm       Brooklyn Nets   \n",
       "4    2013  201212110DET  2012-12-11  7:30 pm     Detroit Pistons   \n",
       "\n",
       "           GuestName  total_score  total_line  game_line  Host_HostRank  \\\n",
       "0          Utah Jazz        227.0       207.5        7.5             13   \n",
       "1    Detroit Pistons        201.0       186.5        5.5             13   \n",
       "2  San Antonio Spurs        240.0       212.0       -7.0             12   \n",
       "3    New York Knicks        197.0       195.5       -3.5             12   \n",
       "4     Denver Nuggets        195.0       203.5       -4.5             11   \n",
       "\n",
       "      ...      gPTS_avg10  gTS%_avg10  g3PAR_avg10  gFTr_avg10  gDRB%_avg10  \\\n",
       "0     ...            99.0      0.5206       0.2230      0.2981        69.22   \n",
       "1     ...            90.3      0.5077       0.2144      0.3095        71.46   \n",
       "2     ...           108.0      0.5915       0.2743      0.2518        74.26   \n",
       "3     ...           100.3      0.5473       0.3595      0.2544        74.23   \n",
       "4     ...           101.1      0.5605       0.2173      0.3177        68.45   \n",
       "\n",
       "   gTRB%_avg10  gAST%_avg10  gSTL%_avg10 gBLK%_avg10 gDRtg_avg10  \n",
       "0        50.05        61.57         8.63       10.31      110.87  \n",
       "1        49.48        59.83         6.48        9.46      107.91  \n",
       "2        50.99        61.82         8.30        6.85      101.41  \n",
       "3        47.88        52.07         9.31        7.64      109.24  \n",
       "4        50.40        56.33         7.67        7.83      114.86  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Season', u'GameId', u'GameDate', u'GameTime', u'HostName',\n",
       "       u'GuestName', u'total_score', u'total_line', u'game_line',\n",
       "       u'Host_HostRank', u'Host_GameRank', u'Guest_GuestRank',\n",
       "       u'Guest_GameRank', u'host_win_count', u'host_lose_count',\n",
       "       u'guest_win_count', u'guest_lose_count', u'game_behind', u'winner',\n",
       "       u'loser', u'host_place_streak', u'guest_place_streak', u'hq1_avg10',\n",
       "       u'hq2_avg10', u'hq3_avg10', u'hq4_avg10', u'hPace_avg10',\n",
       "       u'heFG%_avg10', u'hTOV%_avg10', u'hORB%_avg10', u'hFT/FGA_avg10',\n",
       "       u'hORtg_avg10', u'hFG_avg10', u'hFGA_avg10', u'hFG%_avg10',\n",
       "       u'h3P_avg10', u'h3PA_avg10', u'h3P%_avg10', u'hFT_avg10', u'hFTA_avg10',\n",
       "       u'hFT%_avg10', u'hORB_avg10', u'hDRB_avg10', u'hTRB_avg10',\n",
       "       u'hAST_avg10', u'hSTL_avg10', u'hBLK_avg10', u'hTOV_avg10',\n",
       "       u'hPF_avg10', u'hPTS_avg10', u'hTS%_avg10', u'h3PAR_avg10',\n",
       "       u'hFTr_avg10', u'hDRB%_avg10', u'hTRB%_avg10', u'hAST%_avg10',\n",
       "       u'hSTL%_avg10', u'hBLK%_avg10', u'hDRtg_avg10', u'gq1_avg10',\n",
       "       u'gq2_avg10', u'gq3_avg10', u'gq4_avg10', u'gPace_avg10',\n",
       "       u'geFG%_avg10', u'gTOV%_avg10', u'gORB%_avg10', u'gFT/FGA_avg10',\n",
       "       u'gORtg_avg10', u'gFG_avg10', u'gFGA_avg10', u'gFG%_avg10',\n",
       "       u'g3P_avg10', u'g3PA_avg10', u'g3P%_avg10', u'gFT_avg10', u'gFTA_avg10',\n",
       "       u'gFT%_avg10', u'gORB_avg10', u'gDRB_avg10', u'gTRB_avg10',\n",
       "       u'gAST_avg10', u'gSTL_avg10', u'gBLK_avg10', u'gTOV_avg10',\n",
       "       u'gPF_avg10', u'gPTS_avg10', u'gTS%_avg10', u'g3PAR_avg10',\n",
       "       u'gFTr_avg10', u'gDRB%_avg10', u'gTRB%_avg10', u'gAST%_avg10',\n",
       "       u'gSTL%_avg10', u'gBLK%_avg10', u'gDRtg_avg10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3768, 96)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2013, 2014, 2015, 2016])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Utah Jazz\n",
       "1    Philadelphia 76ers\n",
       "2     San Antonio Spurs\n",
       "3       New York Knicks\n",
       "4        Denver Nuggets\n",
       "Name: winner, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.winner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create our target variable: does the home team win?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['host_wins'] = (data.HostName == data.winner).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictors = [c for c in data.columns if c not in ['GameId','GameDate','GameTime','HostName',\n",
    "                                                   'GuestName','total_score','total_line','game_line',\n",
    "                                                   'winner','loser','host_wins','Season']]\n",
    "X = data[predictors]\n",
    "y = data.host_wins.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the training and testing data\n",
    "- Test data should be the 2016 season data, train data will be the previous seasons.\n",
    "- Make sure to standardize your predictor matrix (easiest to do prior to splitting the data into training and testing... but techinically not totally correct)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Xs[data.Season.isin([2013, 2014, 2015])]\n",
    "X_test = Xs[data.Season == 2016]\n",
    "\n",
    "y_train = y[data.Season.isin([2013, 2014, 2015])]\n",
    "y_test = y[data.Season == 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='fit-knn'></a>\n",
    "\n",
    "## Fitting the default KNN\n",
    "\n",
    "---\n",
    "\n",
    "Below we can fit a default `KNeighborsClassifier` to predict win vs. not on the training data, then score it on the testing data. \n",
    "\n",
    "Make sure to compare your score to the baseline accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57258883248730963"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603045685279\n"
     ]
    }
   ],
   "source": [
    "print np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "> Is this good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Searching for the best hyperparameters\n",
    "\n",
    "\n",
    "Our default KNN performs quite poorly on the test data. But what if we changed the number of neighbors? The weighting? The distance metric?\n",
    "\n",
    "These are all hyperparameters of the KNN. How would we do this manually? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gridsearch pseudocode for our KNN\n",
    "\n",
    "```python\n",
    "accuracies = {}\n",
    "for k in neighbors_to_test:\n",
    "    for w in weightings_to_test:\n",
    "        for d in distance_metrics_to_test:\n",
    "            hyperparam_set = (k, w, d)\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=w, metric=d)\n",
    "            cv_accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "            accuracies[hyperparam_set] = np.mean(cv_accuracies)\n",
    "```\n",
    "\n",
    "In the pseudocode above, we would find the key in the dictionary (a hyperparameter set) that has the larget value (mean cross-validated accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='gscv'></a>\n",
    "### Using `GridSearchCV`\n",
    "\n",
    "This would be an annoying process to have to do manually. Luckily sklearn comes with a convenience class for performing gridsearch:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "The `GridSearchCV` has a handful of important arguments:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | ---|\n",
    "| **`estimator`** | The sklearn instance of the model to fit on |\n",
    "| **`param_grid`** | A dictionary where keys are hyperparameters for the model and values are lists of values to test |\n",
    "| **`cv`** | The number of internal cross-validation folds to run for each set of hyperparameters |\n",
    "| **`n_jobs`** | How many cores to use on your computer to run the folds (-1 means use all cores) |\n",
    "| **`verbose`** | How much output to display (0 is none, 1 is limited, 2 is printouts for every internal fit) |\n",
    "\n",
    "\n",
    "Below is an example for how one might set up the gridsearch for our KNN:\n",
    "\n",
    "```python\n",
    "knn_parameters = {\n",
    "    'n_neighbors':[1,3,5,7,9],\n",
    "    'weights':['uniform','distance']\n",
    "}\n",
    "\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsClassifier(), knn_parameters, verbose=1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Try out the sklearn gridsearch below on the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 3, 5, 9, 15, 21], 'metric': ['euclidean', 'manhattan'], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':[1,3,5,9,15,21],\n",
    "    'weights':['uniform','distance'],\n",
    "    'metric':['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, verbose=1)\n",
    "\n",
    "knn_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='gs-results'></a>\n",
    "### Examining the results of the gridsearch\n",
    "\n",
    "Once the gridsearch has fit (this can take awhile!) we can pull out a variety of information and useful objects from the gridsearch object, stored as attributes:\n",
    "\n",
    "| Property | Use |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays parameters searched over. |\n",
    "| **`results.best_score_`** | Best mean cross-validated score achieved. |\n",
    "| **`results.best_estimator_`** | Reference to model with best score.  Is usable / callable. |\n",
    "| **`results.best_params_`** | The parameters that have been found to perform with the best score. |\n",
    "| **`results.grid_scores_`** | Display score attributes with corresponding parameters. | \n",
    "\n",
    "**Print out the best score found in the search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61264822134387353"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Print out the set of hyperparameters that achieved the best score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 21, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Assign the best fit model (`best_estimator_`) to a variable and score it on the test data.**\n",
    "\n",
    "Compare this model to the baseline accuracy and your default KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62538071065989853"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = knn_gridsearch.best_estimator_\n",
    "best_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.603045685279\n",
      "default KNN: 0.572588832487\n"
     ]
    }
   ],
   "source": [
    "print 'baseline:', np.mean(y_test)\n",
    "print 'default KNN:', knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='caution'></a>\n",
    "\n",
    "## A caution on gridsearching\n",
    "\n",
    "---\n",
    "\n",
    "Sklearn models often have many options/hyperparameters with many different possible values. It may be tempting to search over a wide variety of them. In general, this is not wise.\n",
    "\n",
    "Remember that **gridsearch searches over all possible combinations of hyperparameters in the parameter dictionary!**\n",
    "\n",
    "The KNN model class takes a wider range of options during instantiation than we have explored. Imagine that we had this as our parameter dictionary:\n",
    "\n",
    "```python\n",
    "parameter_grid = {\n",
    "    'n_neighbors':range(1,151),\n",
    "    'weights':['uniform','distance',custom_function],\n",
    "    'algorithm':['ball_tree','kd_tree','brute','auto'],\n",
    "    'leaf_size':range(1,152),\n",
    "    'metric':['minkowski','euclidean'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "```\n",
    "\n",
    "**How many different combinations will need to be tested?\n",
    "\n",
    "| Parameter | Potential Values | Unique Values |\n",
    "| --- | ---| ---: |\n",
    "| **n_neighbors** | int range 1-150 | 150 |\n",
    "| **weights** | strs:  \"uniform\", \"distance\" or user defined function | 3 |\n",
    "| **algorithm** | strs: \"ball_tree\", \"kd_tree\", \"brute\", \"auto\" | 4 |\n",
    "| **leaf_size** | int range 1-151 | 151 |\n",
    "| **metric** | str: \"minkowski\" or 'euclidean' type | 2 |\n",
    "| **p** | int: 1=manhattan_distance, 2= euclidean_distance | 2 |\n",
    "|| <br>_150 \\* 3 \\* 4 \\* 151 \\* 2 \\* 2 = n combinations_ <br><br>| _1,087,200_ |\n",
    "\n",
    "And that is over a million tests *before we even consider the number of cross-validation folds!*\n",
    "\n",
    "If you're not careful, gridsearching can quickly blow up. A lot of the hyperparameters we put in the dumb example above are either redundant or not useful.\n",
    "\n",
    "> **It is extremely important to understand what the hyperparameters do and think critically about what ranges are useful and relevant to your model!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid searching over some hyper-params but over-riding defaults for others\n",
    "\n",
    "If you look at the documentation for KNearestNeighbors, by default, the weights metric is 'uniform' and the number of neighbours is 3.  \n",
    "\n",
    "What if I want to override the weights metric to 'distance' and grid search only through number of neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   28.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=21, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':[1,3,5,9,15,21],\n",
    "}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(weights='distance'), knn_params, cv=5, verbose=1)\n",
    "\n",
    "knn_gridsearch.fit(X_train, y_train)\n",
    "knn_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='practice'></a>\n",
    "\n",
    "## Independent practice: gridsearch regularization penalties with logistic regression\n",
    "\n",
    "---\n",
    "\n",
    "Logistic regression models can also apply the Lasso and Ridge penalties. The `LogisticRegression` class takes these regularization-relevant hyperparameters:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | ---|\n",
    "| **`penalty`** | `'l1'` for Lasso, `'l2'` for Ridge |\n",
    "| **`solver`** | Must be set to `'liblinear'` for the Lasso penalty to work. |\n",
    "| **`C`** | The regularization strength. Equivalent to `1./alpha` |\n",
    "\n",
    "**You should:**\n",
    "1. Fit and validate the accuracy of a default logistic regression on the basketball data.\n",
    "- Perform a gridsearch over different regularization strengths and Lasso and Ridge penalties.\n",
    "- Compare the accuracy on the test set of your optimized logistic regression to the baseline accuracy and the default model.\n",
    "- Look at the best parameters found. What was chosen? What does this suggest about our data?\n",
    "- Look at the (non-zero, if Lasso was selected as best) coefficients and associated predictors for your optimized model. What appears to be the most important predictors of winning the game?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695431472081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603045685279\n"
     ]
    }
   ],
   "source": [
    "print np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default is already much better than KNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the parameters. Looking at C regularization strengths on a log scale.\n",
    "# This takes awhile...\n",
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(LogisticRegression(), gs_params, cv=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   35.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.12332e-05, ...,   8.90215e-01,   1.00000e+00]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66079770032339202"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score on the training data:\n",
    "lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0029836472402833404, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters on the training data:\n",
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lasso was chosen: this indicates that maybe unimportant (noise) variables\n",
    "# is more of an issue in our data than multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign the best estimator to a variable:\n",
    "best_lr = lr_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66598984771573599"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it on the testing data:\n",
    "best_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slightly better than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "        'coef':best_lr.coef_[0],\n",
    "        'feature':X.columns\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df['abs_coef'] = np.abs(coef_df.coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort by absolute value of coefficient (magnitude)\n",
    "coef_df.sort_values('abs_coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.218062</td>\n",
       "      <td>game_behind</td>\n",
       "      <td>0.218062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef      feature  abs_coef\n",
       "8  0.218062  game_behind  0.218062"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-zero coefs and predictors\n",
    "coef_df[coef_df.coef != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independent practice part 2:\n",
    "\n",
    "Recreate the above grid search from scratch to verify that you get the same answer for optimal hyperparams!\n",
    "\n",
    "*hint*: use a for loop, and `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "results = []\n",
    "for pen in gs_params['penalty']:\n",
    "    for c in gs_params['C']:\n",
    "        lr = LogisticRegression(C=c, penalty=pen, solver='liblinear')\n",
    "        results.append((pen, c, cross_val_score(lr, X_train, y_train, cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>c</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.660794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.660794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.660794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.660794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.660794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.659721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.659718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.038535</td>\n",
       "      <td>0.659001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>0.658282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.658280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.034305</td>\n",
       "      <td>0.658280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.657914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.657914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.657912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>0.657552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.657206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.657203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>0.657202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.657196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.656843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.656841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.656836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.656835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.019179</td>\n",
       "      <td>0.656483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.656483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.656475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.656475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.656123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.655767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.655762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.408911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    penalty         c     score\n",
       "49       l1  0.002984  0.660794\n",
       "50       l1  0.003352  0.660794\n",
       "51       l1  0.003765  0.660794\n",
       "52       l1  0.004229  0.660794\n",
       "53       l1  0.004751  0.660794\n",
       "59       l1  0.009545  0.659721\n",
       "67       l1  0.024201  0.659718\n",
       "71       l1  0.038535  0.659001\n",
       "69       l1  0.030539  0.658282\n",
       "72       l1  0.043288  0.658280\n",
       "70       l1  0.034305  0.658280\n",
       "159      l2  0.009545  0.657914\n",
       "160      l2  0.010723  0.657914\n",
       "162      l2  0.013530  0.657912\n",
       "161      l2  0.012045  0.657552\n",
       "58       l1  0.008498  0.657206\n",
       "68       l1  0.027186  0.657203\n",
       "61       l1  0.012045  0.657202\n",
       "158      l2  0.008498  0.657196\n",
       "63       l1  0.015199  0.656843\n",
       "62       l1  0.013530  0.656841\n",
       "157      l2  0.007565  0.656836\n",
       "163      l2  0.015199  0.656835\n",
       "65       l1  0.019179  0.656483\n",
       "66       l1  0.021544  0.656483\n",
       "164      l2  0.017074  0.656475\n",
       "156      l2  0.006734  0.656475\n",
       "64       l1  0.017074  0.656123\n",
       "60       l1  0.010723  0.655767\n",
       "54       l1  0.005337  0.655762\n",
       "..      ...       ...       ...\n",
       "5        l1  0.000018  0.408911\n",
       "4        l1  0.000016  0.408911\n",
       "3        l1  0.000014  0.408911\n",
       "2        l1  0.000013  0.408911\n",
       "23       l1  0.000145  0.408911\n",
       "27       l1  0.000231  0.408911\n",
       "25       l1  0.000183  0.408911\n",
       "26       l1  0.000206  0.408911\n",
       "1        l1  0.000011  0.408911\n",
       "47       l1  0.002364  0.408911\n",
       "46       l1  0.002105  0.408911\n",
       "45       l1  0.001874  0.408911\n",
       "44       l1  0.001668  0.408911\n",
       "43       l1  0.001485  0.408911\n",
       "42       l1  0.001322  0.408911\n",
       "41       l1  0.001177  0.408911\n",
       "40       l1  0.001048  0.408911\n",
       "39       l1  0.000933  0.408911\n",
       "38       l1  0.000830  0.408911\n",
       "37       l1  0.000739  0.408911\n",
       "36       l1  0.000658  0.408911\n",
       "35       l1  0.000586  0.408911\n",
       "34       l1  0.000521  0.408911\n",
       "33       l1  0.000464  0.408911\n",
       "32       l1  0.000413  0.408911\n",
       "31       l1  0.000368  0.408911\n",
       "30       l1  0.000327  0.408911\n",
       "29       l1  0.000292  0.408911\n",
       "28       l1  0.000260  0.408911\n",
       "0        l1  0.000010  0.408911\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized = pd.DataFrame(results, columns=['penalty', 'c', 'score'])\n",
    "optimized.sort_values('score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternate solution - saves space\n",
    "\n",
    "best_c = None\n",
    "best_pen = None\n",
    "best_score = 0\n",
    "for pen in gs_params['penalty']:\n",
    "    for c in gs_params['C']:\n",
    "        lr = LogisticRegression(C=c, penalty=pen, solver='liblinear')\n",
    "        score = cross_val_score(lr, X_train, y_train, cv=5).mean()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_pen = pen\n",
    "            best_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print best_pen, best_c, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
